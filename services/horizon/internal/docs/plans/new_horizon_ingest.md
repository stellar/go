# New Horizon Ingest

This describes the goals, design, and implementation plan for the new Horizon ingestion system.

## Project Goals

- Handle need for Horizon to re-ingest, catch up after outage, or fill gaps
- No more stellar-core DB access from Horizon
- Full history ingestion of Stellar Public Network ledger shouldn’t take longer than 24h on x1.32xlarge AWS machine
- Horizon maintains own state of the ledger. Order books, at least, need to be kept in-memory to allow fast pathfinding.
- Multi-writer ingestion is provided for re-ingestion (speed) and for ledger stream (high availability)
- Ingestion is a collection of micro-services (trade aggregations, trades, txn history, etc…)
- Support plugins, so 3rd parties can implement custom ingestion schemes and easily plug them in
- Can run as standalone process, separate from Horizon
- Has clear API for building clients on top of it

## Design

### Inputs

The ingestion system will read data from two sources:

1. A History Archive <sup>[1](https://www.stellar.org/developers/stellar-core/software/admin.html#history-archives),[2](https://github.com/stellar/stellar-core/blob/master/docs/history.md)</sup>, which is generated by `stellar-core` and provides a complete copy of a recent [ledger](https://www.stellar.org/developers/guides/concepts/ledger.html).
2. A ledger [transaction set](https://www.stellar.org/developers/guides/concepts/transactions.html#transaction-sets) backend, which provides random access to the transaction sets in ledger closes. It is used to construct a history of events on the Stellar network, as well as keep ingestion up to date with new ledger closes.

#### History Archive Reader

The ingestion system needs to provide a full copy of current ledger state so that Horizon and other consumers of the ingestion system have no need to access the `stellar-core` database. The history archive reader allows ingestion to read the (near) current ledger state from a history archive. The advantage of this approach is that ingestion puts no load on the `stellar-core` database to pull in ledger state, since it reads entirely from a history archive, which is often stored in S3 or a separate file system.

For context, a `stellar-core` can be configured to write out a history archive, which stores snapshots of the ledger state every 64 ledgers (approximately every 5 minutes). We envision that an administrator will run a `stellar-core`, configure it to write out a history archive, and then point the ingestion system at that history archive. This has two advantages:

1. The ingestion does not put load on any external service (like SDF's history archives)
2. The administrator does not need to trust third party history archives

Typically, the ingestion system will only access the history archive on startup to get a full copy of ledger state, and will then keep that copy of ledger state up to date using data from the separate ledger transaction set backend. However, the ingestion system could access older snapshots to construct a history of ledger state, or it could periodically re-ingest the full ledger state to detect any errors that accumulate over time from updating the ledger state.

The history archive reader supports multiple backends to handle different ways that a history archive can be stored:

1. S3 backend
2. HTTP backend
3. File backend

UML Class diagram

![History Archive Reader Class Diagram](images/historyarchive.png)

Example of reading a history archive using `stellar-core`:

```sh
wget http://history.stellar.org/prd/core-live/core_live_001/results/01/4d/f7/results-014df7ff.xdr.gz
gunzip results-014df7ff.xdr.gz
~/src/stellar-core/src/stellar-core dump-xdr results-014df7ff.xdr | head -n 40
```

#### Full Ledger Reader

The ingestion system needs a way to keep the current ledger state up to date, as well as a way to construct a history of events (typically transactions, operations, and effects) that have occurred over time on the Stellar network. The full ledger reader provides this ability. Specifically, it allows the ingestion system to access a stream of transaction metadata that encode state changes that happen as a result of every transaction. This information is missing from the history archives, and is also updated after every ledger close (vs. after every 64 in the history archives). The full ledger reader also has access to transaction sets for each ledger.

Here's a summary of the unique features provided by the full ledger reader vs. the history archive reader:

| Reader | ledger state snapshots | transaction metadata | near-realtime (updates at every ledger close) |
| --- | --- | --- | ---|
| history archive | X | | |
| full ledger | | X | X |

The long term plan for the full ledger reader is for `stellar-core` to write transaction metadata out to an S3 bucket, which will allow the following:

1. Reading transaction metadata without creating load on `stellar-core`'s database
2. Fast, parallel access to historical transaction metadata (allowing fast `CATCHUP_COMPLETE` ingestion)
3. Multiple `stellar-core`s writing the latest update to the same S3 object. This allows redundancy: one `stellar-core` can fail, and the stream of S3 objects will continue uninterrupted.

However, this requires a change to `stellar-core`, which is estimated to happen in Q3 2019. Until then, the ingestion system will read from the `txfeehistory` and `txhistory` tables in the `stellar-core` database as it does currently. Unfortunately, we won't get any of the benefits listed above until the change is made to `stellar-core`.

The full ledger reader will support multiple backends:

1. `stellar-core` database reader (this will be implemented first, and is exactly what happens now)
2. File backend
3. S3 backend

UML Class diagram

![Ledger Transaction-Set Reader Class Diagram](images/ledgerbackend.png)
